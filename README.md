# MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation
<p align="center">
<!-- 
<a href="" target='_blank'>
    <img src="">
</a>
-->
<h5 align="center">
    <em>
        <a href="https://scholar.google.com/citations?user=7e0W-2AAAAAJ&hl=en">Weihao Xuan</a><sup>1</sup>, 
        <a href="https://scholar.google.com/citations?user=aCawmg0AAAAJ&hl=zh-CN">Rui Yang</a><sup>2</sup>, 
        <a href="https://scholar.google.com/citations?user=CH-rTXsAAAAJ&hl=en">Heli Qi</a><sup>3</sup>, 
        <a href="https://scholar.google.com/citations?user=i0K71KQAAAAJ&hl=en">Qingcheng Zeng</a><sup>4</sup>, 
        <a href="https://scholar.google.com.hk/citations?user=95n7XTkAAAAJ&hl=en">Yunze Xiao</a><sup>5</sup>, 
        <a href="https://scholar.google.com/citations?user=uOAYTXoAAAAJ&hl=en">Yun Xing</a><sup>6</sup>,
        <br>
        <a href="https://scholar.google.com/citations?user=H58gKSAAAAAJ&hl=en">Junjue Wang</a><sup>1</sup>, 
        <a href="">Huitao Li</a><sup>2</sup>, 
        <a href="">Xin Li</a><sup>2</sup>, 
        <a href="https://scholar.google.com/citations?hl=es&user=uK_esCgAAAAJ">Edison Marrese-Taylor</a><sup>1</sup>, 
        <a href="https://scholar.google.com/citations?user=ceF698kAAAAJ&hl=zh-CN">Nan Liu</a><sup>2</sup>, 
        <a href="https://scholar.google.com/citations?user=FSLotiMAAAAJ&hl=en">Qingyu Chen</a><sup>7</sup>,
        <br>
        <a href="https://scholar.google.com/citations?user=bDgzTucAAAAJ&hl=en">Douglas Teodoro</a><sup>8</sup>, 
        <a href="https://scholar.google.com/citations?user=uYmK-A0AAAAJ&hl=en">Shijian Lu</a><sup>6</sup>, 
        <a href="https://scholar.google.co.jp/citations?user=nRLaJiQAAAAJ&hl=ja">Yusuke Iwasawa</a><sup>1</sup>, 
        <a href="https://scholar.google.co.jp/citations?user=Dy8iau4AAAAJ&hl=ja">Yutaka Matsuo</a><sup>1</sup>, 
        <a href="https://scholar.google.com/citations?user=JuYPjCMAAAAJ&hl=zh-CN">Irene Li</a><sup>1</sup>
    </em>
</h5>
</p>
<p align="center">
  <a href="https://huggingface.co/datasets/li-lab/MMLU-ProX"><img src="https://img.shields.io/badge/ðŸ¤—-Hugging%20Face-yellow" alt="Hugging Face"></a>
  <a href=""><img src="https://img.shields.io/badge/arXiv-Coming%20Soon-b31b1b" alt="arXiv"></a>
</p>
<p align="center">
    <sup>1</sup>The University of Tokyo, <sup>2</sup>NUS-Duke Medical School, <sup>3</sup>Waseda University,<br>
    <sup>4</sup>Northwestern University, <sup>5</sup>Carnegie Mellon University,<br>
    <sup>6</sup>Nanyang Technological University, <sup>7</sup>Yale University, <sup>8</sup>University of Geneva
</p>
<p align="center">

## Overview

_MMLU-ProX_ is a **multilingual** benchmark that builds upon MMLU-Pro, extending to 13 typologically diverse languages, designed to evaluate large language models' reasoning capabilities across linguistic and cultural boundaries.

_MMLU-ProX_ addresses critical limitations in existing multilingual benchmarks by:
- Building upon the challenging, reasoning-focused design of MMLU-Pro
- Extending coverage to 13 typologically diverse languages
- Employing a rigorous semi-automatic translation process with expert validation
- Ensuring conceptual accuracy, terminological consistency, and cultural relevance

## News
- [March 2025] ðŸŽ‰ MMLU-ProX is now available on Hugging Face!
- [March 2025] We are still expanding this dataset to more languages! Stay tuned!


## Usage

Coming soon.

## Citation
Coming soon.

## Contact
For questions or feedback about MMLU-ProX, please open an issue.
